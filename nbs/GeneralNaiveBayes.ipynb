{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn-like api for a general implementation of Naive Bayes\n",
    "\n",
    "## 0. Intro:\n",
    "\n",
    "Although the computations that go into it are very tedious Naive Bayes is one of the more accessible ML classification algorithms out there. The reason for that is it is easy to understand, and it makes __sense__, intuitively speaking.\n",
    "\n",
    "However, the `sklearn` implementations of Naive Bayes are built (excluding `GaussianNB`) with certain assumptions, which make them tough to use without a lot of pre-processing, as we explored in [this post](/multinbvsbinomnb/). In this post, I'd like to implement the Naive Bayes algorithm idea for a general input dataset. I will not optimize the code, so it won't be naturally scalable or anything, the goal is just to hack something together quickly.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Refresher on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/taylanbil/.local/share/jupyter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyter_core\n",
    "\n",
    "jupyter_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temp humidity    wind play\n",
       "0      Sunny   Hot     High    Weak   No\n",
       "1      Sunny   Hot     High  Strong   No\n",
       "2   Overcast   Hot     High    Weak  Yes\n",
       "3       Rain  Mild     High    Weak  Yes\n",
       "4       Rain  Cool   Normal    Weak  Yes\n",
       "5       Rain  Cool   Normal  Strong   No\n",
       "6   Overcast  Cool   Normal  Strong  Yes\n",
       "7      Sunny  Mild     High    Weak   No\n",
       "8      Sunny  Cool   Normal    Weak  Yes\n",
       "9       Rain  Mild   Normal    Weak  Yes\n",
       "10     Sunny  Mild   Normal  Strong  Yes\n",
       "11  Overcast  Mild     High  Strong  Yes\n",
       "12  Overcast   Hot   Normal    Weak  Yes\n",
       "13      Rain  Mild     High  Strong   No"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data is from below. Hardcoding it in order to remove dependency\n",
    "data = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/petehunt/c4.5-compiler/master/example/tennis.csv',\n",
    "    usecols=['outlook', 'temp', 'humidity', 'wind', 'play']\n",
    ")\n",
    "\n",
    "# data = [\n",
    "#     ['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
    "#     ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
    "#     ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
    "#     ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
    "#     ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
    "#     ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
    "#     ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
    "#     ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
    "#     ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
    "#     ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],\n",
    "#     ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],\n",
    "#     ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n",
    "#     ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n",
    "#     ['Rain', 'Mild', 'High', 'Strong', 'No'],\n",
    "# ]\n",
    "# data = pd.DataFrame(data, columns='Outlook,Temperature,Humidity,Wind,PlayTennis'.split(','))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load nb.py\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "__author__ = 'taylanbil'\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from bisect import bisect_right\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Discretizer(object):\n",
    "\n",
    "    def __init__(self, upperlim=20, bottomlim=0, mapping=False):\n",
    "        self.mapping = mapping\n",
    "        self.set_lims(upperlim, bottomlim)\n",
    "\n",
    "    @property\n",
    "    def cutoffs(self):\n",
    "        return [i[0] for i in self.mapping]\n",
    "\n",
    "    def set_lims(self, upperlim, bottomlim):\n",
    "        if not self.mapping:\n",
    "            self.bottomlim = bottomlim\n",
    "            self.upperlim = upperlim\n",
    "        else:\n",
    "            vals = sorted(np.unique(map(itemgetter(1), self.mapping)))\n",
    "            self.bottomlim = vals[0]\n",
    "            self.upperlim = vals[-1]\n",
    "        assert self.bottomlim < self.upperlim\n",
    "\n",
    "    def fit(self, continuous_series, subsample=None):\n",
    "        self.mapping = []\n",
    "        if subsample is not None:\n",
    "            n = len(continuous_series)*subsample if subsample < 1 else subsample\n",
    "            continuous_series = np.random.choice(continuous_series, n, replace=False)\n",
    "        continuous_series = pd.Series(continuous_series).reset_index(drop=1)\n",
    "        ranked = pd.Series(continuous_series).rank(pct=1, method='average')\n",
    "        ranked *= self.upperlim - self.bottomlim\n",
    "        ranked += self.bottomlim\n",
    "        ranked = ranked.map(round)\n",
    "        nvals = sorted(np.unique(ranked))  # sorted in case numpy changes\n",
    "        for nval in nvals:\n",
    "            cond = ranked == nval\n",
    "            self.mapping.append((continuous_series[cond].min(), int(nval)))\n",
    "\n",
    "    def transform_single(self, val):\n",
    "        if not self.mapping:\n",
    "            raise NotImplementedError('Haven\\'t been fitted yet')\n",
    "        elif pd.isnull(val):\n",
    "            return None\n",
    "        i = bisect_right(self.cutoffs, val) - 1\n",
    "        if i == -1:\n",
    "            return 0\n",
    "        return self.mapping[i][1]\n",
    "\n",
    "    def transform(self, vals):\n",
    "        if isinstance(vals, float):\n",
    "            return self.transform_single(vals)\n",
    "        elif vals is None:\n",
    "            return None\n",
    "        return pd.Series(vals).map(self.transform_single)\n",
    "\n",
    "    def fit_transform(self, vals):\n",
    "        self.fit(vals)\n",
    "        return self.transform(vals)\n",
    "\n",
    "\n",
    "class NaiveBayesPreprocessor(object):\n",
    "    \"\"\"\n",
    "    Don't pass in Nans. fill with keyword.\n",
    "    \"\"\"\n",
    "\n",
    "    OTHER = '____OTHER____'\n",
    "    FILLNA = '____NA____'\n",
    "\n",
    "    def __init__(self, alpha=1.0, min_freq=0.01, bins=20):\n",
    "        self.alpha = alpha  # Laplace smoothing\n",
    "        self.min_freq = min_freq  # drop values occuring less frequently than this\n",
    "        self.bins = bins  # number of bins for continuous fields\n",
    "\n",
    "    def learn_continuous_transf(self, series):\n",
    "        D = Discretizer(upperlim=self.bins)\n",
    "        D.fit(series)\n",
    "        return D\n",
    "\n",
    "    def learn_discrete_transf(self, series):\n",
    "        vcs = series.value_counts(dropna=False, normalize=True)\n",
    "        vcs = vcs[vcs >= self.min_freq]\n",
    "        keep = set(vcs.index)\n",
    "        if len(keep) < len(vcs) / 2:\n",
    "            transf = lambda r: r if r in keep else self.OTHER\n",
    "        else:\n",
    "            mask = {fld for fld in vcs.index if fld not in keep}\n",
    "            transf = lambda r: self.OTHER if r in mask else r\n",
    "        return transf\n",
    "\n",
    "    def learn_transf(self, series):\n",
    "        if series.dtype == np.float64:\n",
    "            return self.learn_continuous_transf(series)\n",
    "        else:\n",
    "            return self.learn_discrete_transf(series)\n",
    "\n",
    "    def fit(self, X_orig, y=None):\n",
    "        \"\"\"\n",
    "        Expects pandas series and pandas DataFrame\n",
    "        \"\"\"\n",
    "        X = X_orig.fillna(self.FILLNA)\n",
    "        # get dtypes\n",
    "        self.dtypes = defaultdict(set)\n",
    "        for fld, dtype in X.dtypes.iteritems():\n",
    "            self.dtypes[dtype].add(fld)\n",
    "        # get transfs\n",
    "        self.transformations = {\n",
    "            fld: self.learn_transf(series)\n",
    "            for fld, series in X.iteritems()}\n",
    "\n",
    "    def transform(self, X_orig, y=None):\n",
    "        \"\"\"\n",
    "        Expects pandas series and pandas DataFrame\n",
    "        \"\"\"\n",
    "        X = X_orig.fillna(self.FILLNA)\n",
    "        for fld, func in self.transformations.items():\n",
    "            if isinstance(func, Discretizer):\n",
    "                X[fld] = func.transform(X[fld])\n",
    "            else:\n",
    "                X[fld] = X[fld].map(func)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier(object):\n",
    "\n",
    "    def __init__(self, alpha=1.0, class_priors=None, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        self.class_priors = class_priors\n",
    "\n",
    "    def get_class_log_priors(self, y):\n",
    "        self.classes_ = y.unique()\n",
    "        if self.class_priors is None:\n",
    "            self.class_priors = y.value_counts(normalize=1)\n",
    "        elif isinstance(self.class_priors, str) and self.class_priors == 'equal':\n",
    "            raise NotImplementedError\n",
    "        self.class_log_priors = self.class_priors.map(np.log)\n",
    "\n",
    "    def get_log_likelihoods(self, fld):\n",
    "        table = self.groups[fld].value_counts().unstack(fill_value=0)\n",
    "        table += self.alpha\n",
    "        sums = table.sum(axis=1)\n",
    "        likelihoods = table.apply(lambda r: r/sums, axis=0)\n",
    "        log_likelihoods = likelihoods.applymap(np.log)\n",
    "        return log_likelihoods.to_dict()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = pd.Series(y)\n",
    "        self.get_class_log_priors(y)\n",
    "        self.groups = X.groupby(y)\n",
    "        self.log_likelihoods = {\n",
    "            fld: self.get_log_likelihoods(fld)\n",
    "            for fld, series in X.iteritems()\n",
    "        }\n",
    "\n",
    "    def get_approx_log_posterior(self, series, class_):\n",
    "        log_posterior = self.class_log_priors[class_]  # prior\n",
    "        for fld, val in series.iteritems():\n",
    "            log_posterior += self.log_likelihoods[fld][val][class_]\n",
    "        return log_posterior\n",
    "\n",
    "    def decision_function_series(self, series):\n",
    "        approx_log_posteriors = [\n",
    "            self.get_approx_log_posterior(series, class_)\n",
    "            for class_ in self.classes_]\n",
    "        return pd.Series(approx_log_posteriors, index=self.classes_)\n",
    "\n",
    "    def decision_function_df(self, df):\n",
    "        return df.apply(self.decision_function_series, axis=1)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        returns the log posteriors\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return self.decision_function_df(X)\n",
    "        elif isinstance(X, pd.Series):\n",
    "            return self.decision_function_series(X)\n",
    "        elif isinstance(X, dict):\n",
    "            return self.decision_function_series(pd.Series(X))\n",
    "\n",
    "    def predict_proba(self, X, normalize=True):\n",
    "        \"\"\"\n",
    "        returns the (normalized) posterior probability\n",
    "\n",
    "        normalization is just division by the evidence. doesn't change the argmax.\n",
    "        \"\"\"\n",
    "        log_post = self.decision_function(X)\n",
    "        if isinstance(log_post, pd.Series):\n",
    "            post = log_post.map(np.exp)\n",
    "        elif isinstance(log_post, pd.DataFrame):\n",
    "            post = log_post.applymap(np.exp)\n",
    "        else:\n",
    "            raise NotImplementedError('type of X is \"{}\"'.format(type(X)))\n",
    "        if normalize:\n",
    "            if isinstance(post, pd.Series):\n",
    "                post /= post.sum()\n",
    "            elif isinstance(post, pd.DataFrame):\n",
    "                post = post.div(post.sum(axis=1), axis=0)\n",
    "        return post\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas = self.decision_function(X)\n",
    "        if isinstance(probas, pd.Series):\n",
    "            return np.argmax(probas)\n",
    "        return probas.apply(np.argmax, axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return np.mean(np.array(y) == preds.values)\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier2(NaiveBayesClassifier):\n",
    "\n",
    "    def get_class_log_priors(self, y, weights):\n",
    "        self.classes_ = y.unique()\n",
    "        self.class_priors = {\n",
    "            class_: ((y == class_)*weights).mean()\n",
    "            for class_ in self.classes_}\n",
    "        self.class_log_priors = {\n",
    "            class_: np.log(prior)\n",
    "            for class_, prior in self.class_priors.items()}\n",
    "\n",
    "    def get_log_likelihood(self, y, class_, series, val, vals, weights):\n",
    "        # indices of `series` and `y` and `weights` must be the same\n",
    "        # XXX: what to do with alpha? should we smooth it out somehow?\n",
    "        cond = y == class_\n",
    "        num = ((series.loc[cond] == val) * weights.loc[cond]).sum() + self.alpha\n",
    "        denom = (weights.loc[cond]).sum() + len(vals) * self.alpha\n",
    "        return np.log(num/denom)\n",
    "\n",
    "    def get_log_likelihoods(self, series, y, weights):\n",
    "        vals = series.unique()\n",
    "        y_ = y.reset_index(drop=True, inplace=False)\n",
    "        series_ = series.reset_index(drop=True, inplace=False)\n",
    "        weights_ = weights.reset_index(drop=True, inplace=False)\n",
    "\n",
    "        log_likelihoods = {\n",
    "            val: {class_: self.get_log_likelihood(y_, class_, series_, val, vals, weights_)\n",
    "                  for class_ in self.classes_}\n",
    "            for val in vals}\n",
    "        return log_likelihoods\n",
    "\n",
    "    def fit(self, X, y, weights=None):\n",
    "        if weights is None:\n",
    "            return super(NaiveBayesClassifier2, self).fit(X, y)\n",
    "        weights *= len(weights) / weights.sum()\n",
    "        y = pd.Series(y)\n",
    "        self.get_class_log_priors(y, weights)\n",
    "        self.log_likelihoods = {\n",
    "            fld: self.get_log_likelihoods(series, y, weights)\n",
    "            for fld, series in X.iteritems()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
